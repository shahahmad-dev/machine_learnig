{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### **1. What is Ridge Regression?**\n",
        "\n",
        "Ridge Regression is a type of **linear regression** that helps when we have **multicollinearity** (when features are highly correlated) or when our model **overfits** the training data.\n",
        "\n",
        "Itâ€™s also called **L2 regularization** because it adds a penalty to the square of the coefficients.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Formula**\n",
        "\n",
        "In normal linear regression, we try to **minimize**:\n",
        "\n",
        "[\n",
        "\\text{RSS} = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
        "]\n",
        "\n",
        "Where:\n",
        "\n",
        "* (y_i) = actual value\n",
        "* (\\hat{y}_i) = predicted value\n",
        "\n",
        "In **Ridge Regression**, we minimize:\n",
        "\n",
        "[\n",
        "\\text{RSS} + \\lambda \\sum_{j=1}^p \\beta_j^2\n",
        "]\n",
        "\n",
        "Where:\n",
        "\n",
        "* (\\beta_j) = coefficients\n",
        "* (\\lambda) = regularization parameter (controls penalty)\n",
        "\n",
        "ðŸ’¡ **Key:** Larger (\\lambda) â†’ more penalty â†’ smaller coefficients â†’ less overfitting.\n",
        "If (\\lambda = 0), Ridge becomes normal linear regression.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Why use Ridge Regression?**\n",
        "\n",
        "1. Prevent **overfitting** when there are too many features.\n",
        "2. Handles **multicollinearity** (correlated features).\n",
        "3. Improves **prediction accuracy** on unseen data.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Example in Python**\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Sample data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create Ridge model\n",
        "ridge = Ridge(alpha=1.0)  # alpha is Î»\n",
        "\n",
        "# Train the model\n",
        "ridge.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = ridge.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"MSE:\", mse)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Difference from Lasso**\n",
        "\n",
        "| Feature               | Ridge               | Lasso                                   |\n",
        "| --------------------- | ------------------- | --------------------------------------- |\n",
        "| Regularization        | L2                  | L1                                      |\n",
        "| Coefficient shrinkage | Small values        | Can become 0 (feature selection)        |\n",
        "| Use                   | Prevent overfitting | Feature selection + prevent overfitting |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "7fw4WeJFl2Pj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as  np\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# example data\n",
        "X = np.array([[1, 1, ], [1, 2], [2, 2], [2, 3]])\n",
        "y = np.dot(X, np.array([1,2])) + 3\n",
        "\n",
        "# Ridge Regression model\n",
        "ridge = Ridge(alpha=1.0)\n",
        "ridge.fit(X, y)\n",
        "\n",
        "print(\"Coefficients:\", ridge.coef_)\n",
        "print(\"Intercept:\", ridge.intercept_)\n"
      ],
      "metadata": {
        "id": "MxgDrhBdl6Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ridge Regression VS Liner Regression**\n"
      ],
      "metadata": {
        "id": "IbUK5-hBpIKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries**"
      ],
      "metadata": {
        "id": "MAtlBTv5sfcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# load dataset\n",
        "df = sns.load_dataset('titanic')"
      ],
      "metadata": {
        "id": "-VN0nD2pmrdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "Hf6t0ZRRrhGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "RmMeTIMVsVRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# selecting a subset of columns for simplicity\n",
        "columns_to_use = ['survived','pclass', 'sex', 'age','fare']\n",
        "df = df[columns_to_use]\n",
        "\n",
        "# handling missing values\n",
        "df['age'].fillna(df['age'].mean())\n",
        "\n",
        "# train test split\n",
        "X = df.drop('survived', axis=1)\n",
        "y = df['survived']\n",
        "\n",
        "# train test split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ude_dCcdp8iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating a Pipeline**"
      ],
      "metadata": {
        "id": "U94BmxlEsPSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a pipline for OneHotEncoding and Model\n",
        "categorical_feature = ['sex']\n",
        "numeric_feature = ['pclass', 'age', 'fare']\n",
        "\n",
        "# Preprocessor\n",
        "Preprocessor = ChildProcessError(\n",
        "    transformers = [\n",
        "        ('num', 'passthrough', numeric_feature),\n",
        "        ('cat', OneHotEncoder(), categorical_feature)\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "# linear regresion pipline\n",
        "\n",
        "linear_reg_pipe = Pipeline(\n",
        "    steps = [\n",
        "        ('preprocessor', Preprocessor),\n",
        "        ('regressor', LinearRegression())\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "# Ridge regression pipline\n",
        "\n",
        "ridge_reg_pipe = Pipeline(\n",
        "    steps = [\n",
        "        ('preprocessor', Preprocessor),\n",
        "        ('regressor', Ridge(alpha=1.0))\n",
        "    ]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "1ehWQTlsrVSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r092CN8VtGsf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}