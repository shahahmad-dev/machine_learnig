{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VFKGsotg1Hn"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "df = sns.load_dataset('titanic')"
      ],
      "metadata": {
        "id": "qlFYWk7Yh5lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the missing values\n",
        "df.isnull().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "yjWH_3uDiBSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ðŸ§¹ **1. Impute Missing Values using Mean, Median, and Mode**\n",
        "\n",
        "Missing values can reduce model accuracy and cause bias.\n",
        "**Imputation** replaces missing values with statistical estimates.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Mean Imputation**\n",
        "\n",
        "* Used for **numerical data**\n",
        "* Best when data has **no extreme outliers**\n",
        "\n",
        "```python\n",
        "df['age'] = df['age'].fillna(df['age'].mean())\n",
        "```\n",
        "\n",
        "#### âœ… Positive Points\n",
        "\n",
        "* Simple and fast âš¡\n",
        "* Keeps dataset size unchanged\n",
        "* Works well for normally distributed data\n",
        "\n",
        "#### âŒ Negative Points\n",
        "\n",
        "* Affected by outliers â—\n",
        "* Reduces data variability\n",
        "* Can introduce bias if data is skewed\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Median Imputation**\n",
        "\n",
        "* Used for **numerical data**\n",
        "* Best when data contains **outliers**\n",
        "\n",
        "```python\n",
        "df['age'] = df['age'].fillna(df['age'].median())\n",
        "```\n",
        "\n",
        "#### âœ… Positive Points\n",
        "\n",
        "* Robust to outliers âš–ï¸\n",
        "* Better for skewed distributions\n",
        "* More reliable than mean in real-world data\n",
        "\n",
        "#### âŒ Negative Points\n",
        "\n",
        "* Ignores relationships between features\n",
        "* Still reduces variability\n",
        "* Slightly less efficient for normal data\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Mode Imputation**\n",
        "\n",
        "* Used for **categorical data**\n",
        "* Replaces missing values with the **most frequent value**\n",
        "\n",
        "```python\n",
        "df['gender'] = df['gender'].fillna(df['gender'].mode()[0])\n",
        "```\n",
        "\n",
        "#### âœ… Positive Points\n",
        "\n",
        "* Best choice for categorical features ðŸ·ï¸\n",
        "* Easy to implement\n",
        "* Maintains valid category values\n",
        "\n",
        "#### âŒ Negative Points\n",
        "\n",
        "* Can over-represent one category\n",
        "* Increases class imbalance\n",
        "* May hide important patterns\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Œ **Summary Table**\n",
        "\n",
        "| Method | Best For                | Pros                   | Cons                       |\n",
        "| ------ | ----------------------- | ---------------------- | -------------------------- |\n",
        "| Mean   | Numeric (no outliers)   | Fast, simple           | Sensitive to outliers      |\n",
        "| Median | Numeric (with outliers) | Robust                 | Less efficient             |\n",
        "| Mode   | Categorical             | Easy, valid categories | Bias toward frequent class |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "sQJKFk1_k2zN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['age'] = df['age'].fillna(df['age'].mean())"
      ],
      "metadata": {
        "id": "7PQxvczAiFTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the missing values\n",
        "df.isnull().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "alTv9VC2iijH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filling categorical values the mode(most frequent value)\n",
        "df['embarked'] = df['embarked'].fillna(df['embarked'].mode()[0])\n",
        "df['embark_town'] = df['embark_town'].fillna(df['embark_town'].mode()[0])\n",
        "df['deck'] = df['deck'].fillna(df['deck'].mode()[0])"
      ],
      "metadata": {
        "id": "zNRLc1taiksm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the missing values\n",
        "df.isnull().sum().sort_values(ascending=False)\n"
      ],
      "metadata": {
        "id": "3eNw3W05j4Wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ðŸ” **2. K-Nearest Neighbors (KNN) Imputation**\n",
        "\n",
        "**KNN Imputer** fills missing values by looking at the **K nearest samples** (neighbors) based on feature similarity.\n",
        "The missing value is replaced using the **average (or most common value)** of its neighbors.\n",
        "\n",
        "ðŸ“Œ Works mainly with **numerical data**.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **How KNN Imputation Works**\n",
        "\n",
        "1. Find the **K nearest rows** using distance (usually Euclidean).\n",
        "2. Use neighborsâ€™ values to estimate the missing value.\n",
        "3. Replace missing value with the computed result.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Example Code**\n",
        "\n",
        "```python\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "df[['age', 'salary']] = imputer.fit_transform(df[['age', 'salary']])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… **Positive Points**\n",
        "\n",
        "* Uses relationships between features ðŸ§ \n",
        "* More accurate than mean/median in many cases\n",
        "* Preserves data patterns\n",
        "* Good for complex datasets\n",
        "\n",
        "---\n",
        "\n",
        "## âŒ **Negative Points**\n",
        "\n",
        "* Works only with numerical data â—\n",
        "* Computationally expensive for large datasets ðŸ¢\n",
        "* Sensitive to feature scaling\n",
        "* Not suitable for high missing-rate data\n",
        "\n",
        "---\n",
        "\n",
        "## âš ï¸ **Important Notes**\n",
        "\n",
        "* Always **scale data** before using KNN Imputer\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "```\n",
        "\n",
        "* Categorical data must be encoded first (but results may be misleading)\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Œ **When to Use KNN Imputer**\n",
        "\n",
        "| Situation                    | Recommendation |\n",
        "| ---------------------------- | -------------- |\n",
        "| Small to medium dataset      | âœ… Use KNN      |\n",
        "| Strong feature relationships | âœ… Use KNN      |\n",
        "| Large dataset                | âŒ Avoid        |\n",
        "| Categorical features         | âŒ Avoid        |\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ” **Comparison with Mean/Median**\n",
        "\n",
        "| Method        | Uses Feature Relationships | Speed   | Accuracy |\n",
        "| ------------- | -------------------------- | ------- | -------- |\n",
        "| Mean / Median | âŒ No                       | âš¡ Fast  | Medium   |\n",
        "| KNN Imputer   | âœ… Yes                      | ðŸ¢ Slow | High     |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "rQVMyXn_lAmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "3Z2LCSOSmAaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "df  = sns.load_dataset('titanic')\n",
        "\n",
        "from sklearn.impute  import KNNImputer\n",
        "\n",
        "imputer = KNNImputer(n_neighbors=4)\n",
        "\n",
        "\n",
        "df['age'] = imputer.fit_transform(df[['age']])\n"
      ],
      "metadata": {
        "id": "SUeYxcUxlOsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ðŸ“ˆ **3. Regression Imputation**\n",
        "\n",
        "**Regression Imputer** estimates missing values by **predicting them using other features** through a regression model.\n",
        "\n",
        "ðŸ“Œ Best suited for **numerical features** with strong relationships to other variables.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **How Regression Imputation Works**\n",
        "\n",
        "1. Select the feature with missing values (target).\n",
        "2. Use remaining features as predictors.\n",
        "3. Train a regression model on non-missing data.\n",
        "4. Predict and replace missing values.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Example Code**\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# separate complete and missing data\n",
        "complete = df[df['age'].notna()]\n",
        "missing = df[df['age'].isna()]\n",
        "\n",
        "X_train = complete.drop(columns='age')\n",
        "y_train = complete['age']\n",
        "\n",
        "X_test = missing.drop(columns='age')\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "df.loc[df['age'].isna(), 'age'] = model.predict(X_test)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… **Positive Points**\n",
        "\n",
        "* Uses relationships between features ðŸ§ \n",
        "* More accurate than mean/median\n",
        "* Preserves data trends\n",
        "* Works well when variables are correlated\n",
        "\n",
        "---\n",
        "\n",
        "## âŒ **Negative Points**\n",
        "\n",
        "* Assumes linear relationship â—\n",
        "* Overfits if data is noisy\n",
        "* Ignores uncertainty in predictions\n",
        "* Computationally expensive\n",
        "\n",
        "---\n",
        "\n",
        "## âš ï¸ **Important Notes**\n",
        "\n",
        "* Only for **numerical features**\n",
        "* Handle outliers before applying\n",
        "* Scale features if needed\n",
        "* Risk of data leakage if applied incorrectly\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Œ **When to Use Regression Imputer**\n",
        "\n",
        "| Situation                  | Recommendation |\n",
        "| -------------------------- | -------------- |\n",
        "| Strong feature correlation | âœ… Use          |\n",
        "| Small missing percentage   | âœ… Use          |\n",
        "| Weak relationship          | âŒ Avoid        |\n",
        "| Categorical features       | âŒ Avoid        |\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ” **Comparison with Other Imputers**\n",
        "\n",
        "| Method             | Uses Relationships | Complexity | Accuracy |\n",
        "| ------------------ | ------------------ | ---------- | -------- |\n",
        "| Mean / Median      | âŒ No               | Low        | Low      |\n",
        "| KNN Imputer        | âœ… Yes              | Medium     | High     |\n",
        "| Regression Imputer | âœ… Yes              | High       | High     |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "Sb5Qx85upcfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = sns.load_dataset('titanic')"
      ],
      "metadata": {
        "id": "yT4kn5g9q9sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "mDooTPBhrbbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "imputer = IterativeImputer(max_iter=10)\n",
        "\n",
        "df['age'] = imputer.fit_transform(df[['age']])"
      ],
      "metadata": {
        "id": "cMTuzAdgpaTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "XPKoUUp8rByz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ðŸŒ³ **4.Random Forest Imputer**\n",
        "\n",
        "**Random Forest Imputer** is a **regression-based imputer** that uses a **Random Forest model** to predict missing values.\n",
        "It can handle **non-linear relationships** between features, unlike simple linear regression imputation. âœ…\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  **How It Works (Step-by-Step)**\n",
        "\n",
        "1. Select a column with missing values â†’ **target**\n",
        "2. Use remaining columns â†’ **predictors**\n",
        "3. Train a **Random Forest model** on rows without missing values\n",
        "4. Predict missing values for the target column\n",
        "5. Repeat for all columns with missing data\n",
        "6. Optionally, iterate to improve predictions (like MICE) ðŸ”„\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ’» **Example Code (Using `fancyimpute`)**\n",
        "\n",
        "> Note: Scikit-learn doesnâ€™t have a direct Random Forest imputer. Use `fancyimpute` for this.\n",
        "\n",
        "```python\n",
        "!pip install fancyimpute\n",
        "\n",
        "from fancyimpute import IterativeImputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import pandas as pd\n",
        "\n",
        "imputer = IterativeImputer(\n",
        "    estimator=RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    max_iter=10\n",
        ")\n",
        "\n",
        "df_imputed = imputer.fit_transform(df)\n",
        "df = pd.DataFrame(df_imputed, columns=df.columns)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… **Advantages**\n",
        "\n",
        "* Handles **non-linear relationships** ðŸŒ³\n",
        "* Can impute **multiple columns** at once\n",
        "* Iterative approach improves **accuracy**\n",
        "\n",
        "---\n",
        "\n",
        "## âŒ **Disadvantages**\n",
        "\n",
        "* **Computationally expensive** ðŸ¢\n",
        "* Slow on **large datasets**\n",
        "* Works **best with numerical data**\n",
        "* Categorical data needs **encoding first**\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ†š **Comparison Table**\n",
        "\n",
        "| Imputer                       | Type              | Advantage                         | Limitation                    |\n",
        "| ----------------------------- | ----------------- | --------------------------------- | ----------------------------- |\n",
        "| Mean/Median                   | Simple            | Fast                              | Ignores feature relationships |\n",
        "| KNN                           | Neighbors         | Uses similarity                   | Sensitive to scaling          |\n",
        "| Iterative (Linear Regression) | Regression        | Uses correlation                  | Assumes linearity             |\n",
        "| **Random Forest Imputer**     | Regression (Tree) | Handles non-linear, more accurate | Slow, numerical only          |\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸŽ¯ **Summary**\n",
        "\n",
        "> Random Forest Imputer is an advanced regression-based technique that predicts missing values using Random Forest, capturing **non-linear relationships** between features.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Cl2NmUDTHFuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "df.drop('deck', axis=1, inplace=True)\n",
        "\n",
        "df.isnull().sum().sort_values(ascending=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "PFpBPFZCroT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode the data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "# columns to encode\n",
        "columns_to_encode = ['alone','adult_male','sex','embarked', \"who\" , 'class', 'embark_town', 'alive']\n",
        "\n",
        "#dictionary to store LabelEncoder to each columns\n",
        "lable_encoders = {}\n",
        "\n",
        "# loop to apply LabelEncoder for the columns\n",
        "for col in columns_to_encode:\n",
        "\n",
        "  # create the LabelEncoder\n",
        "  le = LabelEncoder()\n",
        "\n",
        "  # fit and transform the data\n",
        "  df[col] = le.fit_transform(df[col])\n",
        "\n",
        "  # store the encoders in dictionary\n",
        "  lable_encoders[col] = le\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "ZjBekmaeH4dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the dataset into two parts: one with missing values , one withot\n",
        "df_with_missing = df[df['age'].isna()]\n",
        "# dropna remove all rows with missing values\n",
        "df_without_missing = df.dropna()\n"
      ],
      "metadata": {
        "id": "4FvFrUDCI4gX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The shape of the original dataset is:', df.shape)\n",
        "print('The shape of the dataset with missing values is:', df_with_missing.shape)\n",
        "print('The shape of the dataset without missing values is:', df_without_missing.shape)\n"
      ],
      "metadata": {
        "id": "LrC9t94rNXsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_missing.head()"
      ],
      "metadata": {
        "id": "i4rBYuMeNsuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into X and y\n",
        "X = df_without_missing.drop(['age'], axis=1)\n",
        "y = df_without_missing['age']\n",
        "\n",
        "# split the data into train test and split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Random Forest Imputer\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# evaluate the model\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print('Mean Squared Error:', mse)\n",
        "print('Mean Absolute Error:', mae)\n",
        "print('R2 Score:', r2)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# predict the missing values\n",
        "y_pred = rf_model.predict(df_with_missing.drop(['age'], axis=1))\n",
        "\n",
        "# replace the missing values with the prediction values\n",
        "df_with_missing['age'] = y_pred\n",
        "\n",
        "# check the missing values\n",
        "df_with_missing.isnull().sum().sort_values(ascending=False)\n",
        "\n",
        "# concate the two dataframe\n",
        "df_complete = pd.concat([df_without_missing, df_with_missing])\n",
        "\n",
        "df_complete.head()\n",
        "\n",
        "# reverse encoding\n",
        "for col in columns_to_encode:\n",
        "  # Retrieve the corresponding LabelEncoder for the column\n",
        "  le = lable_encoders[col]\n",
        "\n",
        "  # inverse transfrom the data\n",
        "  df_complete[col] = le.inverse_transform(df[col])\n",
        "\n",
        "df_complete.head()"
      ],
      "metadata": {
        "id": "SG2q1eeZOPas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ðŸ”¹ **What is MICE Imputer?**\n",
        "\n",
        "**MICE** stands for:\n",
        "\n",
        "> **Multiple Imputation by Chained Equations**\n",
        "\n",
        "It is an **advanced imputer** that fills missing values **iteratively using regression models**.\n",
        "Basically, it predicts missing values in a **column using other columns**, then repeats this process for all columns multiple times to improve accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ **How MICE Works (Step-by-Step)**\n",
        "\n",
        "1. Pick a column with missing values â†’ **target**\n",
        "2. Use other columns â†’ **predictors**\n",
        "3. Train a **regression model** on rows without missing values\n",
        "4. Predict missing values for that column\n",
        "5. Move to the next column with missing values\n",
        "6. Repeat this process **multiple iterations** until values converge\n",
        "\n",
        "This is why itâ€™s also called **Iterative Imputer** in sklearn âœ…\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ **Python Example**\n",
        "\n",
        "```python\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'age': [25, None, 30, None],\n",
        "    'salary': [50000, 60000, 55000, 65000]\n",
        "})\n",
        "\n",
        "# Create MICE/Iterative Imputer\n",
        "imputer = IterativeImputer(max_iter=10, random_state=42)\n",
        "\n",
        "# Fit and transform the data\n",
        "df_imputed = imputer.fit_transform(df)\n",
        "df = pd.DataFrame(df_imputed, columns=df.columns)\n",
        "\n",
        "print(df)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "\n",
        "```\n",
        "    age   salary\n",
        "0  25.0  50000.0\n",
        "1  27.5  60000.0\n",
        "2  30.0  55000.0\n",
        "3  28.5  65000.0\n",
        "```\n",
        "\n",
        "* Missing ages are predicted using the **relationship with salary**\n",
        "* Iteratively improves predictions across columns\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… **Advantages**\n",
        "\n",
        "* Uses **feature relationships** â†’ more accurate than mean/median\n",
        "* Works with **multiple columns at once**\n",
        "* Handles **complex datasets**\n",
        "\n",
        "---\n",
        "\n",
        "## âŒ **Disadvantages**\n",
        "\n",
        "* Computationally **expensive** ðŸ¢\n",
        "* Only works with **numerical data**\n",
        "* Needs **careful preprocessing** (e.g., scaling)\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ **Summary**\n",
        "\n",
        "> **MICE/Iterative Imputer** = advanced regression-based imputer that predicts missing values iteratively using all other features.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "xKBadFTSVVmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Select numeric columns only\n",
        "numeric_cols = ['age', 'fare', 'sibsp', 'parch']\n",
        "\n",
        "# Create MICE/Iterative Imputer\n",
        "imputer = IterativeImputer(max_iter=10, random_state=42)\n",
        "\n",
        "# Fit and transform numeric columns\n",
        "df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
        "\n",
        "# Check result\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "8MgdoH18VYsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jlx0ms-YVdbM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}